name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        python-version: [ "3.10" ]
        include:
          - os: ubuntu-latest
    steps:  
    - name: Checkout the code
      uses: actions/checkout@v3
  
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install the Pico Toolchain
      run: |
          sudo DEBIAN_FRONTEND=noninteractive apt update
          sudo DEBIAN_FRONTEND=noninteractive apt install -y cmake gcc-arm-none-eabi libnewlib-arm-none-eabi build-essential libstdc++-arm-none-eabi-newlib
    
    - name: Install AtariST Toolkit Docker image
      run: curl -sL https://github.com/sidecartridge/atarist-toolkit-docker/releases/download/v1.0.0/install_atarist_toolkit_docker.sh | bash

    - name: Run - remove interactive
      run: sed -i 's/-it//' /usr/local/bin/stcmd

    - name: Run - Build PICO_W release version
      run: ./build.sh pico_w release image

    - name: Run - Build PICO_W debug version
      run: ./build.sh pico_w debug

    - name: Get version from version.txt
      id: get_version
      run: echo "RELEASE_VERSION=$(cat version.txt)" >> $GITHUB_ENV

    - name: Upload the binaries to release
      uses: svenstaro/upload-release-action@v2
      with:
        repo_token: ${{ secrets.GITHUB_TOKEN }}
        file: dist/*
        tag: ${{ github.ref }}
        release_name: ${{ env.RELEASE_VERSION }}
        file_glob: true
        overwrite: true
        make_latest: true

    - name: Install boto3 for S3 upload
      run: |
        python3 -m pip install --upgrade pip
        pip3 install boto3

    - name: Upload artifacts to S3
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-east-1
      run: |
        python3 <<EOF
        import os
        import boto3

        s3 = boto3.client('s3')
        release_dir = 'dist'
        bucket_name = 'atarist.sidecartridge.com'

        files_to_upload = [
          ('SIDECARTVERSION', 'text/plain'),
          ('upgrade.bin', 'application/octet-stream'),
        ]

        for fname, content_type in files_to_upload:
          local_path = os.path.join(release_dir, fname)
          if not os.path.isfile(local_path):
            print(f"Skipping {fname}: not found at {local_path}")
            continue
          s3_path = fname  # upload at bucket root
          print(f"Uploading {local_path} to s3://{bucket_name}/{s3_path}")
          s3.upload_file(
            local_path,
            bucket_name,
            s3_path,
            ExtraArgs={"ContentType": content_type}
          )
        EOF
